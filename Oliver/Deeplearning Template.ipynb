{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/og016\n",
      "3.7.3 (default, Apr  3 2019, 05:39:12) \n",
      "[GCC 8.3.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path, PosixPath\n",
    "\n",
    "print(Path.home())\n",
    "import pandas.plotting\n",
    "import mysql.connector # pip install mysql-connector-python-rf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf \n",
    "#import git # pip install GitPython\n",
    "import os\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====>GPU Available:  True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.config' has no attribute 'gpu_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c286a73da76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_device_placement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#tf.config.experimental.set_memory_growth( True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGIT_VERSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.config' has no attribute 'gpu_options'"
     ]
    }
   ],
   "source": [
    "print(\"=====>GPU Available: \", tf.test.is_gpu_available())\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.config.experimental.list_physical_devices()\n",
    "#tf.config.gpu_options.allow_growth = True \n",
    "#tf.config.experimental.set_memory_growth( True)\n",
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        \n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(\"=====>\", len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Log Data\n",
    "print('Modification:')\n",
    "modification = input() # Was wurde verÃ¤ndert\n",
    "print('User:')\n",
    "user = input()#git.util.get_user_id() # Bearbeiter, Sollte automatisch gelesen werden \n",
    "try:\n",
    "    repo = git.Repo()\n",
    "    branch = repo.active_branch # Projekt, Sollte automatisch gelesen werden\n",
    "    lastCommit = repo.head.commit.hexsha #\"ca324dadsa\" # Stand, Sollte automatisch gelesen werden\n",
    "except:\n",
    "    print('Branch:')\n",
    "    \n",
    "    branch = input()\n",
    "    lastCommit = ''\n",
    "env = \"local\" # Test umgebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Config\n",
    "samplesize = 1000 # Datensatz\n",
    "split = 0.8  # Testdatensatz in % => 0.8 = 80% testdata\n",
    "BATCH_SIZE = 20\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(os.path.join(Path.home(), 'Pictures/Pictures_Bicycles'))\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "CLASS_NAMES = []\n",
    "for f in np.array([item.name for item in data_dir.glob('Training/*')]):\n",
    "    if f.startswith('uni'):\n",
    "        name = f.split('_')[0]\n",
    "    else:\n",
    "        name = f.split('_')[1]\n",
    "    if name not in CLASS_NAMES :\n",
    "        CLASS_NAMES.append(name)\n",
    "print(CLASS_NAMES)\n",
    "print(image_count)\n",
    "\n",
    "def showBatch(image_batch, label_batch, prediction=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(10):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        ax.imshow(image_batch[n])\n",
    "        if label_batch is not None:\n",
    "            plt.title(CLASS_NAMES[label_batch[n]])\n",
    "        if prediction is not None:\n",
    "            plt.title(CLASS_NAMES[np.argmax(prediction[n])])\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "def getLabel(path):\n",
    "    # geht class name from last folder\n",
    "    #folder = os.path.basename(os.path.dirname(path))\n",
    "    # gets the index of the classname\n",
    "    #return tf.convert_to_tensor(np.where(CLASS_NAMES == folder)[0][0], dtype=tf.int32)\n",
    "    path = Path(path).stem\n",
    "    if str(path).startswith('uni'):\n",
    "        folder = str(path).split('_')[0]\n",
    "    else:\n",
    "        folder = str(path).split('_')[1]\n",
    "        \n",
    "    return tf.convert_to_tensor(CLASS_NAMES.index(folder), dtype=tf.int32)\n",
    "        \n",
    "def loadImg(path):\n",
    "    try:\n",
    "        img = tf.io.read_file(str(path))\n",
    "        img = tf.image.decode_image(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    except:\n",
    "        return path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(role='train'):\n",
    "    #list_ds = tf.data.Dataset.list_files(os.path.join(str(data_dir),'*','*.jpg'))\n",
    "    #ds = list_ds.map(loadImg, num_parallel_calls=AUTOTUNE)\n",
    "    data = Path(os.path.join(data_dir, role)) \n",
    "    paths = list(data.glob('*.jpg'))\n",
    "    #myImage.loadData(pfad)\n",
    "    #remove false jpg's\n",
    "    images = []\n",
    "    for p in paths:\n",
    "        out = loadImg(p)\n",
    "        if type(out) == PosixPath:\n",
    "            paths.remove(out)\n",
    "        else:\n",
    "            images.append(out)\n",
    "    #images = list(map(loadImg, paths))\n",
    "    labels = list(map(getLabel, paths))\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ##Prepare for Training \n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "train_ds = loadDataset('Training')\n",
    "#validate_ds = loadDataset('validate')\n",
    "test_ds = loadDataset('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "## Start Timer \n",
    "start = time.time()\n",
    "val_max_acc = 2 # amount of loops with max acc til stop \n",
    "\n",
    "for n in range(5):\n",
    "    img_batch, label_batch = next(iter(train_ds))\n",
    "    model.fit(img_batch, label_batch, epochs=10)\n",
    "\n",
    "\n",
    "    timg_batch, tlabel_batch = next(iter(validate_ds))\n",
    "    test_loss, test_acc = model.evaluate(timg_batch,  tlabel_batch, verbose=2)\n",
    "    \n",
    "## End Timer\n",
    "end = time.time()\n",
    "runtime = end-start\n",
    "\n",
    "print('\\nTest accuracy: {}, \\nRuntime: {}'.format(test_acc, runtime))\n",
    "\n",
    "\n",
    "images, rlabel_batch = next(iter(test_ds))\n",
    "predictions = model.predict(images)\n",
    "showBatch(images.numpy(), None, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 10 # Laufzeit aus tf\n",
    "maxAcc = 0.85 # Acc. aus tf\n",
    "maxLoss = 0.2 # Loss aus tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
